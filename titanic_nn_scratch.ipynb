{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "PREPROCESSING\n",
    "'''\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "def clean(df, thresh):\n",
    "\n",
    "    # DROP SHIT\n",
    "    df.drop(['PassengerId', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "    # CLEAN FURTHER\n",
    "    lst = ['Mr.','Mrs.','Master.','Miss.']\n",
    "    count =0\n",
    "    for i in range(len(df)):\n",
    "        i += thresh\n",
    "        \n",
    "        # EXTRACT NAME\n",
    "        l = df.Name[i].split(' ')\n",
    "        for j in l:\n",
    "            if j.strip() in lst:\n",
    "                df.Name[i] = j.strip()[:-1]\n",
    "                count +=1\n",
    "                break\n",
    "            df.Name[i] = ''\n",
    "\n",
    "        # FILL NAME\n",
    "        if df.Name[i] == '':\n",
    "            if df.Sex[i]=='male':\n",
    "                if df.Age[i]>=18:\n",
    "                    df.Name[i]='Mr'\n",
    "                else:\n",
    "                    df.Name[i]='Master'\n",
    "            elif df.Sex[i]=='female':\n",
    "                if df.Age[i]>=18:\n",
    "                    df.Name[i]='Mrs'\n",
    "                else:\n",
    "                    df.Name[i]='Miss'\n",
    "\n",
    "        # FILL AGE\n",
    "        if not(df.Age[i]>0.001):\n",
    "            if df.Name[i]=='Mr' or df.Name[i]=='Mrs':\n",
    "                df.Age[i]=np.random.choice(range(20,50))\n",
    "            else:\n",
    "                df.Age[i]=np.random.choice(range(5,18))\n",
    "        \n",
    "    # MAKE NUMERIC\n",
    "    df.replace({'Sex':{'male':0,'female':1}, 'Embarked':{'S':-1,'C':0,'Q':1},\\\n",
    "                'Name':{'Mr':-1,'Mrs':1,'Master':-0.5,'Miss':0.5}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATASET FUNCTIONS\n",
    "def get_train_data():\n",
    "    df = df_train[:720]\n",
    "    clean(df, 0)\n",
    "    x = df.drop(['Survived'], axis=1)\n",
    "    x = (x - x.mean())/(x.max()-x.min())\n",
    "    y = df.loc[:,'Survived']\n",
    "    x = x.values\n",
    "    y = y.values\n",
    "    y = np.expand_dims(y, axis=1)\n",
    "    return x,y\n",
    "\n",
    "def get_val_data():\n",
    "    df = df_train[720:]\n",
    "    clean(df, 720)\n",
    "    x = df.drop(['Survived'], axis=1)\n",
    "    x = (x - x.mean())/(x.max()-x.min())\n",
    "    y = df.loc[:,'Survived']\n",
    "    x = x.values\n",
    "    y = y.values\n",
    "    y = np.expand_dims(y, axis=1)\n",
    "    return x,y\n",
    "\n",
    "def get_test_data():\n",
    "    df = df_test\n",
    "    clean(df, 0)\n",
    "    x = df\n",
    "    x = (x - x.mean())/(x.max()-x.min())\n",
    "    x = x.values\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA\n",
    "train_data, train_labels = get_train_data()\n",
    "val_data, val_labels = get_val_data()\n",
    "test_data = get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data (720, 8) train_label (720, 1)\n",
      "val_data (171, 8) val_label (171, 1)\n",
      "test_data (418, 8)\n"
     ]
    }
   ],
   "source": [
    "# CHECK SHAPES\n",
    "print ('train_data', train_data.shape, 'train_label', train_labels.shape)\n",
    "print ('val_data', val_data.shape, 'val_label', val_labels.shape)\n",
    "print ('test_data', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAINING PARAMETERS                       \n",
    "num_epochs = 100000\n",
    "display_epoch = 2000\n",
    "num_samples = train_data.shape[0]\n",
    "num_attrib=train_data.shape[1]\n",
    "batch_size = 16\n",
    "lr = 1e-4\n",
    "num_hidden=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SIGMOID ACTIVATION AND ITS DERIVATIVE\n",
    "def activate(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "def d_activation(x):\n",
    "    return x * (1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WEIGHTS AND BIASES\n",
    "weight_i_h = np.random.random((num_attrib, num_hidden)) - 0.3\n",
    "weight_h_o = np.random.random((num_hidden,1)) - 0.1\n",
    "bias_i_h = np.random.random((num_hidden)) + 0.2\n",
    "bias_h_o = np.random.random((1)) + 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in progress...\n",
      "Epoch: 00001  Loss: 7.9691142798  Training Accuracy: 0.50000\n",
      "Epoch: 02000  Loss: 5.8902202109  Training Accuracy: 0.81250\n",
      "Epoch: 04000  Loss: 4.7790904040  Training Accuracy: 0.81250\n",
      "Epoch: 06000  Loss: 4.4328237113  Training Accuracy: 0.81250\n",
      "Epoch: 08000  Loss: 4.2514062935  Training Accuracy: 0.81250\n",
      "Epoch: 10000  Loss: 4.1353998644  Training Accuracy: 0.81250\n",
      "Epoch: 12000  Loss: 4.0578665582  Training Accuracy: 0.81250\n",
      "Epoch: 14000  Loss: 4.0051760736  Training Accuracy: 0.81250\n",
      "Epoch: 16000  Loss: 3.9688953713  Training Accuracy: 0.81250\n",
      "Epoch: 18000  Loss: 3.9436738170  Training Accuracy: 0.81250\n",
      "Epoch: 20000  Loss: 3.9260637385  Training Accuracy: 0.81250\n",
      "Epoch: 22000  Loss: 3.9137820698  Training Accuracy: 0.81250\n",
      "Epoch: 24000  Loss: 3.9052673809  Training Accuracy: 0.81250\n",
      "Epoch: 26000  Loss: 3.8994192509  Training Accuracy: 0.81250\n",
      "Epoch: 28000  Loss: 3.8954433750  Training Accuracy: 0.81250\n",
      "Epoch: 30000  Loss: 3.8927568501  Training Accuracy: 0.81250\n",
      "Epoch: 32000  Loss: 3.8909279685  Training Accuracy: 0.81250\n",
      "Epoch: 34000  Loss: 3.8896362320  Training Accuracy: 0.81250\n",
      "Epoch: 36000  Loss: 3.8886445863  Training Accuracy: 0.81250\n",
      "Epoch: 38000  Loss: 3.8877793310  Training Accuracy: 0.81250\n",
      "Epoch: 40000  Loss: 3.8869150786  Training Accuracy: 0.81250\n",
      "Epoch: 42000  Loss: 3.8859632071  Training Accuracy: 0.81250\n",
      "Epoch: 44000  Loss: 3.8848628578  Training Accuracy: 0.81250\n",
      "Epoch: 46000  Loss: 3.8835738704  Training Accuracy: 0.81250\n",
      "Epoch: 48000  Loss: 3.8820712453  Training Accuracy: 0.81250\n",
      "Epoch: 50000  Loss: 3.8803408307  Training Accuracy: 0.81250\n",
      "Epoch: 52000  Loss: 3.8783760042  Training Accuracy: 0.81250\n",
      "Epoch: 54000  Loss: 3.8761751576  Training Accuracy: 0.81250\n",
      "Epoch: 56000  Loss: 3.8737398270  Training Accuracy: 0.81250\n",
      "Epoch: 58000  Loss: 3.8710733339  Training Accuracy: 0.81250\n",
      "Epoch: 60000  Loss: 3.8681798237  Training Accuracy: 0.81250\n",
      "Epoch: 62000  Loss: 3.8650636107  Training Accuracy: 0.75000\n",
      "Epoch: 64000  Loss: 3.8617287518  Training Accuracy: 0.75000\n",
      "Epoch: 66000  Loss: 3.8581787905  Training Accuracy: 0.75000\n",
      "Epoch: 68000  Loss: 3.8544166252  Training Accuracy: 0.75000\n",
      "Epoch: 70000  Loss: 3.8504444682  Training Accuracy: 0.75000\n",
      "Epoch: 72000  Loss: 3.8462638705  Training Accuracy: 0.75000\n",
      "Epoch: 74000  Loss: 3.8418757959  Training Accuracy: 0.75000\n",
      "Epoch: 76000  Loss: 3.8372807336  Training Accuracy: 0.75000\n",
      "Epoch: 78000  Loss: 3.8324788402  Training Accuracy: 0.75000\n",
      "Epoch: 80000  Loss: 3.8274701070  Training Accuracy: 0.75000\n",
      "Epoch: 82000  Loss: 3.8222545477  Training Accuracy: 0.75000\n",
      "Epoch: 84000  Loss: 3.8168323990  Training Accuracy: 0.75000\n",
      "Epoch: 86000  Loss: 3.8112043323  Training Accuracy: 0.81250\n",
      "Epoch: 88000  Loss: 3.8053716650  Training Accuracy: 0.81250\n",
      "Epoch: 90000  Loss: 3.7993365656  Training Accuracy: 0.81250\n",
      "Epoch: 92000  Loss: 3.7931022435  Training Accuracy: 0.81250\n",
      "Epoch: 94000  Loss: 3.7866731123  Training Accuracy: 0.81250\n",
      "Epoch: 96000  Loss: 3.7800549194  Training Accuracy: 0.81250\n",
      "Epoch: 98000  Loss: 3.7732548337  Training Accuracy: 0.81250\n",
      "Epoch: 100000  Loss: 3.7662814856  Training Accuracy: 0.81250\n",
      "Model Trained !\n"
     ]
    }
   ],
   "source": [
    "# EMPTY LISTS TO STORE EPOCH, LOSS AND ACCURACY\n",
    "ep, lo, ac = [], [], []\n",
    "\n",
    "# TRAINING\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    \n",
    "    for batch in range(num_samples/batch_size):\n",
    "        \n",
    "        # FORWARD PROPAGATON\n",
    "        input_layer = train_data[batch_size*batch: batch_size*(batch+1)]\n",
    "        hidden_layer = activate(np.dot(input_layer, weight_i_h) + bias_i_h)\n",
    "        output_layer = activate(np.dot(hidden_layer, weight_h_o) + bias_h_o)\n",
    "        output_train_labels = train_labels[batch_size*batch: batch_size*(batch+1)]\n",
    "\n",
    "        loss = output_layer - output_train_labels\n",
    "        \n",
    "        # BACKWARD PROPAGATION\n",
    "        weight_i_h -= lr * input_layer.T.dot(((loss * d_activation(output_layer)).dot(weight_h_o.T)) * d_activation(hidden_layer))\n",
    "        bias_i_h -= lr * sum(((loss * d_activation(output_layer)).dot(weight_h_o.T)) * d_activation(hidden_layer))\n",
    "        weight_h_o -= lr * hidden_layer.T.dot(loss * d_activation(output_layer))\n",
    "        bias_h_o -= lr * sum(loss * d_activation(output_layer))\n",
    "    \n",
    "    # ACCURACY\n",
    "    x_, y_ = train_data[batch_size*batch: batch_size*(batch+1)], train_labels[batch_size*batch: batch_size*(batch+1)]\n",
    "    prediction = activate((activate(x_.dot(weight_i_h) + bias_i_h)).dot(weight_h_o) + bias_h_o)\n",
    "    prediction = (np.round(prediction, decimals=0)).astype(int)\n",
    "    acc = np.mean(np.equal(y_, prediction))\n",
    "    \n",
    "    # STORE CHECKPOINTS\n",
    "    if epoch == 1:\n",
    "        print ('Training in progress...')\n",
    "        print ('Epoch:', '%05d' % (epoch), ' Loss: {0:.10f}'.format((sum(abs(loss)))[0]), ' Training Accuracy: {0:.5f}'.format(acc))\n",
    "    if epoch % display_epoch == 0:\n",
    "        print ('Epoch:', '%05d' % (epoch), ' Loss: {0:.10f}'.format((sum(abs(loss)))[0]), ' Training Accuracy: {0:.5f}'.format(acc))\n",
    "        ep.append(epoch)\n",
    "        lo.append((sum(abs(loss)))[0])\n",
    "        ac.append(acc)\n",
    "\n",
    "print ('Model Trained !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Graph --\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpKgpCAiIgn/H0pQp6ep4WL2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f41dc19ec90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT\n",
    "print ('Training Graph --')\n",
    "plt.plot(ep, lo, 'k-', label = 'Loss')\n",
    "plt.legend()\n",
    "plt.title('Drop in loss with Epochs')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy --\n",
      "0.859649122807\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION\n",
    "val_data, val_label = get_val_data()\n",
    "prediction = activate((activate(val_data.dot(weight_i_h) + bias_i_h)).dot(weight_h_o) + bias_h_o)\n",
    "print ('Validation Accuracy --')\n",
    "prediction = (np.round(prediction, decimals=0)).astype(int)\n",
    "acc = np.mean(np.equal(val_label, prediction))\n",
    "print (acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Predictions --\n",
      "[138] survived out of 418\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "test = test_data\n",
    "prediction = activate((activate(test.dot(weight_i_h) + bias_i_h)).dot(weight_h_o) + bias_h_o)\n",
    "print ('Test Predictions --')\n",
    "prediction = (np.round(prediction, decimals=0)).astype(int)\n",
    "print (sum(prediction), 'survived out of', len(test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
